{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 3D Face recognition\n",
        "\n",
        "This work is for face recognition / verification for 3D facial images. The file utilizes (at least on the current setting) LFW data base, which celebratires images database, we used it because we can get multiple images for the sane subject. The final Pipeline is as follows: \n",
        "\n",
        "Input raw image >> Face detection >> 3D reconstruction (3D rendered image) >> recognition / verification\n",
        "\n",
        "The steps will be explained accordingly"
      ],
      "metadata": {
        "id": "bSpIhot9qLCY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First part\n",
        "### Dataset preparation\n",
        "\n",
        "This part will mainly focus on downloading the database and filter it out. The filtration is done by the number of images in the each folder, currently, minimum of 7 images were selected, 3 images will be used for testing and the rest for reconstruction and training."
      ],
      "metadata": {
        "id": "3Fsro1U1rVkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading and extracting database\n",
        "import os\n",
        "\n",
        "dataset_dir = '/content/datasets/lfw'\n",
        "if not os.path.exists(dataset_dir):\n",
        "    os.makedirs(dataset_dir)\n",
        "\n",
        "os.chdir('/content/datasets/lfw')\n",
        "\n",
        "!pwd\n",
        "!wget http://vis-www.cs.umass.edu/lfw/lfw-deepfunneled.tgz\n",
        "!tar zxvf lfw-deepfunneled.tgz"
      ],
      "metadata": {
        "id": "8yGa1zvivitG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering the database based on the total number of  images in each subject  \n",
        "!pwd # Just checking the path\n",
        "\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "\n",
        "\n",
        "num_imgs = 7\n",
        "num_train = 5\n",
        "\n",
        "root_path = './lfw-deepfunneled/*'\n",
        "output_train_dir = './train'\n",
        "output_test_dir = './test'\n",
        "\n",
        "if not os.path.exists(output_train_dir):\n",
        "    os.makedirs(output_train_dir)\n",
        "\n",
        "if not os.path.exists(output_test_dir):\n",
        "    os.makedirs(output_test_dir)\n",
        "\n",
        "root_contents = glob.glob(root_path)\n",
        "\n",
        "separator = os.path.sep\n",
        "\n",
        "all_base_names = []\n",
        "for this_dir in root_contents:\n",
        "    if os.path.isdir(this_dir) and len(glob.glob(this_dir + '/*')) >= num_imgs:\n",
        "      \n",
        "      this_dir_base_name = this_dir.split(separator)[-1]\n",
        "      all_base_names.append(this_dir_base_name)\n",
        "      if not os.path.exists(os.path.join(output_train_dir, this_dir_base_name)):\n",
        "          os.makedirs(os.path.join(output_train_dir, this_dir_base_name))\n",
        "          \n",
        "      if not os.path.exists(os.path.join(output_test_dir, this_dir_base_name)):\n",
        "          os.makedirs(os.path.join(output_test_dir, this_dir_base_name))\n",
        "\n",
        "      this_dir_contents = glob.glob(this_dir + '/*')\n",
        "      for i, this_img in enumerate(this_dir_contents):\n",
        "        # print(i, this_img)\n",
        "        if i <= num_train:\n",
        "          # print('This is training img', i, this_img)\n",
        "          shutil.copy(this_img, os.path.join(output_train_dir, this_dir_base_name))\n",
        "        if i > num_train and i <= num_imgs:\n",
        "          # print('This is test img', i, this_img)\n",
        "          shutil.copy(this_img, os.path.join(output_test_dir, this_dir_base_name))"
      ],
      "metadata": {
        "id": "ZeRJkdMDvmQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, dataset preparation is done, we need to pass the data to the next stage, which is face detection\n",
        "\n",
        "For the face detection, a model called DeepFace will be used, and will also be used in the latest recognition phase."
      ],
      "metadata": {
        "id": "Wndpj9tVz9gb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare deepface repo and MTCNN\n",
        "# DeepFace library can perform several tasks \n",
        "!pip install deepface\n",
        "!pip install mtcnn\n",
        "\n",
        "\n",
        "# print(this_dir)"
      ],
      "metadata": {
        "id": "Ru61-svs0abA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Face detection and face landmarks detection\n",
        "\n",
        "For face detection, the final model I have utilized is the MTCNN model, it generate a JSON file with the bounding box and 5 points facial main landmarks, those landmarks are used subsequently for the 3D reconstruction of the face.\n",
        "\n",
        "\n",
        "At this stage a number of images are selected to form the training database, just for testing purposes, the default setting in real world to include all of the subjects\n",
        "\n"
      ],
      "metadata": {
        "id": "vA_daafaTZeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mtcnn import MTCNN\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "\n",
        "\n",
        "def landmarks_to_file(dir_path):\n",
        "\n",
        "  detections_path = os.path.join(dir_path, 'detections')\n",
        "  if not os.path.exists(detections_path):\n",
        "    os.makedirs(detections_path)\n",
        "\n",
        "  landmarks_detector = MTCNN()\n",
        "  img_paths = glob.glob(dir_path + '/*.jpg')\n",
        "  for img_path in img_paths:\n",
        "    landmarks = landmarks_detector.detect_faces(cv2.imread(img_path, cv2.COLOR_BGR2RGB))\n",
        "    img_base_name = img_path.split(os.path.sep)[-1].split('.')[0]\n",
        "    if len(landmarks) > 0:\n",
        "      with open(os.path.join(detections_path, img_base_name + '.txt'), 'w') as f:\n",
        "        for value in landmarks[0]['keypoints']:\n",
        "          f.write('{0} {1}\\n'.format(landmarks[0]['keypoints'][value][0], \n",
        "                                  landmarks[0]['keypoints'][value][1]))\n",
        "\n",
        "num_working_imgs = 10\n",
        "random.shuffle(all_base_names)\n",
        "\n",
        "database_train_root = '/content/datasets/lfw/train'\n",
        "database_test_root = '/content/datasets/lfw/test'\n",
        "\n",
        "select_subjects = []\n",
        "for i in range(len(all_base_names)):\n",
        "  if i <= num_working_imgs:\n",
        "    select_subjects.append(all_base_names[i])\n",
        "    \n",
        "    this_train_dir = os.path.join(database_train_root, all_base_names[i])\n",
        "    this_test_dir = os.path.join(database_test_root, all_base_names[i])\n",
        "\n",
        "    landmarks_to_file(this_train_dir)\n",
        "    landmarks_to_file(this_test_dir)\n",
        "\n",
        "print('Selected images for database:')\n",
        "for i in select_subjects:\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "6gJrjOAD1H4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing GitHub repo and the depenceies for 3D part"
      ],
      "metadata": {
        "id": "Xg25O5GeMAgd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjHurptSL0O4"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content')\n",
        "!git clone https://github.com/sicxu/Deep3DFaceRecon_pytorch.git\n",
        "!pip install pillow argparse\n",
        "!pip install kornia\n",
        "!pip install dominate\n",
        "!pip install trimesh\n",
        "!pip install ninja"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "\n",
        "face_recon_root = '/content/Deep3DFaceRecon_pytorch/'\n",
        "\n",
        "# if not os.path.exists(face_recon_root):\n",
        "#     os.makedirs(face_recon_root)\n",
        "os.chdir(face_recon_root)\n",
        "\n",
        "!git clone https://github.com/NVlabs/nvdiffrast\n",
        "\n",
        "\n",
        "os.chdir('/content/Deep3DFaceRecon_pytorch/nvdiffrast')\n",
        "!pip install ."
      ],
      "metadata": {
        "id": "pc5ntEz1MSFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/Deep3DFaceRecon_pytorch/')\n",
        "!git clone https://github.com/deepinsight/insightface.git\n",
        "!cp -r ./insightface/recognition/arcface_torch ./models/"
      ],
      "metadata": {
        "id": "CmtJzeXzMjg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if not os.path.exists('/content/Deep3DFaceRecon_pytorch/BFM'):\n",
        "#     os.makedirs('/content/Deep3DFaceRecon_pytorch/BFM')\n",
        "os.chdir('/content/Deep3DFaceRecon_pytorch/BFM')\n",
        "\n",
        "\n",
        "!wget https://www.dropbox.com/s/rzx3ajx8dcvft5m/morph_model.zip\n",
        "!unzip morph_model.zip\n",
        "\n",
        "!wget https://www.dropbox.com/s/isx5qs1emhjza38/Exp_Pca.zip\n",
        "!unzip Exp_Pca.zip"
      ],
      "metadata": {
        "id": "BqXCJxRYiCJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/Deep3DFaceRecon_pytorch/checkpoints/face_3d_recon/')\n",
        "os.chdir('/content/Deep3DFaceRecon_pytorch/checkpoints/face_3d_recon/')\n",
        "!wget https://www.dropbox.com/s/wkp6oaceux7tah6/face_recon_feat0.2_augment-20221005T062920Z-001.zip\n",
        "!unzip face_recon_feat0.2_augment-20221005T062920Z-001.zip\n",
        "\n",
        "import shutil\n",
        "shutil.move('./face_recon_feat0.2_augment/epoch_20.pth', '.')"
      ],
      "metadata": {
        "id": "TQt5Iv-x0BXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, render the training data to create the database\n",
        "os.chdir('/content/Deep3DFaceRecon_pytorch')\n",
        "\n",
        "for i in select_subjects:\n",
        "  dir_path = os.path.join(database_train_root, i)\n",
        "  print('python test.py --name=face_3d_recon --epoch=20 --img_folder={0}'.format(dir_path))\n",
        "  os.system('python test.py --name=face_3d_recon --epoch=20 --img_folder={0}'.format(dir_path))"
      ],
      "metadata": {
        "id": "d4EofwU3J5zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9kJkIUK1cFFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def crop_and_copy(dist_dir, in_str):\n",
        "  \n",
        "  if not os.path.exists(dist_dir):\n",
        "    os.makedirs(dist_dir)\n",
        "\n",
        "  os.chdir('/content/Deep3DFaceRecon_pytorch/checkpoints/face_3d_recon/')\n",
        "  all_images = glob.glob('./results/{0}/*/*.png'.format(in_str))\n",
        "  \n",
        "\n",
        "  if in_str == 'test':\n",
        "    all_images = glob.glob('./results/epoch*/*.png')\n",
        "    print('here with', all_images)\n",
        "\n",
        "  for j in all_images:\n",
        "    this_image = cv2.imread(j)\n",
        "    this_image = this_image[:,223:224+223]\n",
        "    image_base = j.split(os.path.sep)[-1].split('.')[0] + '.jpg'\n",
        "    cv2.imwrite(dist_dir + image_base, this_image)  \n",
        "crop_and_copy('/content/datasets/3d_recon_train/', '*')    "
      ],
      "metadata": {
        "id": "qqBMClt5pipE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# os.chdir('/content/Deep3DFaceRecon_pytorch/checkpoints/face_3d_recon/')\n",
        "# !ls \n",
        "# shutil.make_archive('Results', 'zip', './results')"
      ],
      "metadata": {
        "id": "w-e7Yki4RZf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "def render_an_image(img_path):\n",
        "\n",
        "  if not os.path.exists('/content/datasets/test/'):\n",
        "    os.makedirs('/content/datasets/test/')\n",
        "\n",
        "  shutil.copy(img_path, '/content/datasets/test/')\n",
        "\n",
        "  landmarks_to_file('/content/datasets/test/')\n",
        "  \n",
        "  try:\n",
        "    if os.path.exists(glob.glob('./results/epoch*')[0]):\n",
        "      shutil.rmtree(glob.glob('./results/epoch*')[0])\n",
        "  except:\n",
        "    pass\n",
        "  \n",
        "  os.chdir('/content/Deep3DFaceRecon_pytorch/')\n",
        "  os.system('python test.py --name=face_3d_recon --epoch=20 --img_folder=/content/datasets/test/')\n",
        "\n",
        "  if os.path.exists('/content/datasets/test_recon'):\n",
        "    shutil.rmtree('/content/datasets/test_recon')\n",
        "\n",
        "  crop_and_copy('/content/datasets/test_recon/', 'test')\n",
        "\n",
        "  shutil.rmtree('/content/datasets/test/')\n",
        "\n",
        "\n",
        "from deepface import DeepFace\n",
        "def recognize_face(img_path, dataset_path, threshold):\n",
        "  print('==============\\n', img_path, '\\n============')\n",
        "\n",
        "  df_result1 = DeepFace.find(img_path, dataset_path)\n",
        "  # print(df_result1.head)\n",
        "  minimum = df_result1[df_result1.columns[1]][0]\n",
        "  if minimum < threshold:\n",
        "    print('Input image {0} is recognized as {1}'.format(img_path.split(os.path.sep)[-1], df_result1[df_result1.columns[0]][0].split(os.path.sep)[-1]))\n",
        "    return df_result1[df_result1.columns[0]][0], df_result1\n",
        "\n",
        "  else:\n",
        "    print('Subject is not recognized closest matches are listed below:')\n",
        "    print(print(df_result1.head))\n",
        "    return False, df_result1\n",
        "\n",
        "import random\n",
        "all_test_imgs = glob.glob(database_test_root + '/*/*')\n",
        "existing_subject = random.choice(glob.glob(os.path.join(database_test_root, random.choice(select_subjects), '*.*')))\n",
        "random_img = random.choice(all_test_imgs)\n",
        "search_path = '/content/datasets/3d_recon_train'\n",
        "# print(random_img)\n",
        "render_an_image(existing_subject)\n",
        "recognition, df_result1 = recognize_face(glob.glob('/content/datasets/test_recon/*')[0], search_path, 0.25)"
      ],
      "metadata": {
        "id": "BLO3MGD3vQor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_result1"
      ],
      "metadata": {
        "id": "vcclYL8g405f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nJ6-amMM4m_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_result1"
      ],
      "metadata": {
        "id": "C_VCOkCRX1Wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# os.chdir('/content/Deep3DFaceRecon_pytorch/')\n",
        "# !python test.py --name=face_3d_recon --epoch=20 --img_folder='/content/datasets/test/test_1/'"
      ],
      "metadata": {
        "id": "hWwK-kaLYC9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CO3pbRgX7SUA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}